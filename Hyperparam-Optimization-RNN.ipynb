{"cells":[{"cell_type":"markdown","source":["![](https://news.dna3.com.mx/wp-content/uploads/2020/12/cenace-logo.png)\n# Hyperparameter Optimization\n\nEn esta libreta se integra lo necesario para realizar la optimización de hiperparametros con Optuna y la librería neuralForecast. Registrando todo en MLFlow"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"967293ca-4234-49e2-bf06-0b17f61f90b2","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Importando bibliotecas necesarias"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"66cce269-e5ae-4153-b279-d372b7a99a88","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Probando NeuralForecast"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"48985f87-929c-4399-a250-41f0165559f5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["!pip install NeuralForecast"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"66302be0-6f4e-4736-a45c-94f5092141e7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Collecting NeuralForecast\r\n  Using cached neuralforecast-1.1.0-py3-none-any.whl (85 kB)\r\nRequirement already satisfied: torch>=1.12.1 in /databricks/python3/lib/python3.9/site-packages (from NeuralForecast) (1.12.1+cu113)\r\nCollecting numpy>=1.21.6\r\n  Using cached numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\r\nCollecting pandas>=1.3.5\r\n  Using cached pandas-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\r\nCollecting ray[tune]==2.0.1\r\n  Using cached ray-2.0.1-cp39-cp39-manylinux2014_x86_64.whl (60.2 MB)\r\nCollecting pytorch-lightning==1.6.5\r\n  Using cached pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\r\nCollecting rich\r\n  Using cached rich-12.6.0-py3-none-any.whl (237 kB)\r\nRequirement already satisfied: tensorboard>=2.2.0 in /databricks/python3/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->NeuralForecast) (2.9.1)\r\nRequirement already satisfied: tqdm>=4.57.0 in /databricks/python3/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->NeuralForecast) (4.62.3)\r\nCollecting typing-extensions>=4.0.0\r\n  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\r\nCollecting pyDeprecate>=0.3.1\r\n  Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\r\nRequirement already satisfied: protobuf<=3.20.1 in /databricks/python3/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->NeuralForecast) (3.19.4)\r\nRequirement already satisfied: packaging>=17.0 in /databricks/python3/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->NeuralForecast) (21.0)\r\nCollecting torchmetrics>=0.4.1\r\n  Using cached torchmetrics-0.11.0-py3-none-any.whl (512 kB)\r\nRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /databricks/python3/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->NeuralForecast) (2021.8.1)\r\nRequirement already satisfied: PyYAML>=5.4 in /databricks/python3/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->NeuralForecast) (6.0)\r\nCollecting msgpack<2.0.0,>=1.0.0\r\n  Using cached msgpack-1.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\r\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.9/site-packages (from ray[tune]==2.0.1->NeuralForecast) (3.3.1)\r\nCollecting grpcio<=1.43.0,>=1.32.0\r\n  Using cached grpcio-1.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\r\nRequirement already satisfied: attrs in /databricks/python3/lib/python3.9/site-packages (from ray[tune]==2.0.1->NeuralForecast) (21.2.0)\r\nCollecting aiosignal\r\n  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\nCollecting frozenlist\r\n  Using cached frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\r\nRequirement already satisfied: click<=8.0.4,>=7.0 in /databricks/python3/lib/python3.9/site-packages (from ray[tune]==2.0.1->NeuralForecast) (8.0.3)\r\nRequirement already satisfied: virtualenv in /usr/local/lib/python3.9/dist-packages (from ray[tune]==2.0.1->NeuralForecast) (20.8.0)\r\nRequirement already satisfied: requests in /databricks/python3/lib/python3.9/site-packages (from ray[tune]==2.0.1->NeuralForecast) (2.26.0)\r\nRequirement already satisfied: jsonschema in /databricks/python3/lib/python3.9/site-packages (from ray[tune]==2.0.1->NeuralForecast) (3.2.0)\r\nRequirement already satisfied: tabulate in /databricks/python3/lib/python3.9/site-packages (from ray[tune]==2.0.1->NeuralForecast) (0.8.9)\r\nCollecting tensorboardX>=1.9\r\n  Using cached tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\r\nCollecting aiohttp\r\n  Using cached aiohttp-3.8.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\r\nRequirement already satisfied: six>=1.5.2 in /databricks/python3/lib/python3.9/site-packages (from grpcio<=1.43.0,>=1.32.0->ray[tune]==2.0.1->NeuralForecast) (1.16.0)\r\nRequirement already satisfied: pyparsing>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=17.0->pytorch-lightning==1.6.5->NeuralForecast) (3.0.4)\r\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.9/site-packages (from pandas>=1.3.5->NeuralForecast) (2.8.2)\r\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.9/site-packages (from pandas>=1.3.5->NeuralForecast) (2021.3)\r\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (58.0.4)\r\nRequirement already satisfied: markdown>=2.6.8 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (3.3.6)\r\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (0.6.1)\r\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (0.4.6)\r\nRequirement already satisfied: absl-py>=0.4 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (1.0.0)\r\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (1.8.1)\r\nRequirement already satisfied: werkzeug>=1.0.1 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (2.0.2)\r\nRequirement already satisfied: wheel>=0.26 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (0.37.0)\r\nRequirement already satisfied: google-auth<3,>=1.6.3 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (2.6.0)\r\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (5.2.0)\r\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (4.9)\r\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (0.2.8)\r\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /databricks/python3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (1.3.1)\r\nRequirement already satisfied: importlib-metadata>=4.4 in /databricks/python3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (4.8.1)\r\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (3.6.0)\r\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (0.4.8)\r\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests->ray[tune]==2.0.1->NeuralForecast) (3.2)\r\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests->ray[tune]==2.0.1->NeuralForecast) (2.0.4)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests->ray[tune]==2.0.1->NeuralForecast) (1.26.7)\r\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests->ray[tune]==2.0.1->NeuralForecast) (2021.10.8)\r\nRequirement already satisfied: oauthlib>=3.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (3.2.0)\r\nCollecting yarl<2.0,>=1.0\r\n  Using cached yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\r\nCollecting async-timeout<5.0,>=4.0.0a3\r\n  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\r\nCollecting multidict<7.0,>=4.5\r\n  Using cached multidict-6.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\r\nRequirement already satisfied: pyrsistent>=0.14.0 in /databricks/python3/lib/python3.9/site-packages (from jsonschema->ray[tune]==2.0.1->NeuralForecast) (0.18.0)\r\nCollecting commonmark<0.10.0,>=0.9.0\r\n  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\r\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /databricks/python3/lib/python3.9/site-packages (from rich->NeuralForecast) (2.10.0)\r\nRequirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.9/dist-packages (from virtualenv->ray[tune]==2.0.1->NeuralForecast) (2.5.2)\r\nRequirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.9/dist-packages (from virtualenv->ray[tune]==2.0.1->NeuralForecast) (0.3.6)\r\nRequirement already satisfied: backports.entry-points-selectable>=1.0.4 in /usr/local/lib/python3.9/dist-packages (from virtualenv->ray[tune]==2.0.1->NeuralForecast) (1.1.1)\r\nInstalling collected packages: multidict, frozenlist, yarl, typing-extensions, async-timeout, aiosignal, numpy, msgpack, grpcio, aiohttp, torchmetrics, tensorboardX, ray, pyDeprecate, pandas, commonmark, rich, pytorch-lightning, NeuralForecast\r\n  Attempting uninstall: typing-extensions\r\n    Found existing installation: typing-extensions 3.10.0.2\r\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15\r\n    Can't uninstall 'typing-extensions'. No files were found to uninstall.\r\n  Attempting uninstall: numpy\r\n    Found existing installation: numpy 1.20.3\r\n    Not uninstalling numpy at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15\r\n    Can't uninstall 'numpy'. No files were found to uninstall.\r\n  Attempting uninstall: grpcio\r\n    Found existing installation: grpcio 1.44.0\r\n    Not uninstalling grpcio at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15\r\n    Can't uninstall 'grpcio'. No files were found to uninstall.\r\n  Attempting uninstall: pandas\r\n    Found existing installation: pandas 1.3.4\r\n    Not uninstalling pandas at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15\r\n    Can't uninstall 'pandas'. No files were found to uninstall.\r\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\npetastorm 0.11.4 requires pyspark>=2.1.0, which is not installed.\r\nscipy 1.7.1 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.5 which is incompatible.\r\nnumba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.23.5 which is incompatible.\r\nmleap 0.20.0 requires scikit-learn<0.23.0,>=0.22.0, but you have scikit-learn 0.24.2 which is incompatible.\u001B[0m\r\nSuccessfully installed NeuralForecast-1.1.0 aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 commonmark-0.9.1 frozenlist-1.3.3 grpcio-1.43.0 msgpack-1.0.4 multidict-6.0.3 numpy-1.23.5 pandas-1.5.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.5 ray-2.0.1 rich-12.6.0 tensorboardX-2.5.1 torchmetrics-0.11.0 typing-extensions-4.4.0 yarl-1.8.2\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Collecting NeuralForecast\r\n  Using cached neuralforecast-1.1.0-py3-none-any.whl (85 kB)\r\nRequirement already satisfied: torch>=1.12.1 in /databricks/python3/lib/python3.9/site-packages (from NeuralForecast) (1.12.1+cu113)\r\nCollecting numpy>=1.21.6\r\n  Using cached numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\r\nCollecting pandas>=1.3.5\r\n  Using cached pandas-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\r\nCollecting ray[tune]==2.0.1\r\n  Using cached ray-2.0.1-cp39-cp39-manylinux2014_x86_64.whl (60.2 MB)\r\nCollecting pytorch-lightning==1.6.5\r\n  Using cached pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\r\nCollecting rich\r\n  Using cached rich-12.6.0-py3-none-any.whl (237 kB)\r\nRequirement already satisfied: tensorboard>=2.2.0 in /databricks/python3/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->NeuralForecast) (2.9.1)\r\nRequirement already satisfied: tqdm>=4.57.0 in /databricks/python3/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->NeuralForecast) (4.62.3)\r\nCollecting typing-extensions>=4.0.0\r\n  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\r\nCollecting pyDeprecate>=0.3.1\r\n  Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\r\nRequirement already satisfied: protobuf<=3.20.1 in /databricks/python3/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->NeuralForecast) (3.19.4)\r\nRequirement already satisfied: packaging>=17.0 in /databricks/python3/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->NeuralForecast) (21.0)\r\nCollecting torchmetrics>=0.4.1\r\n  Using cached torchmetrics-0.11.0-py3-none-any.whl (512 kB)\r\nRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /databricks/python3/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->NeuralForecast) (2021.8.1)\r\nRequirement already satisfied: PyYAML>=5.4 in /databricks/python3/lib/python3.9/site-packages (from pytorch-lightning==1.6.5->NeuralForecast) (6.0)\r\nCollecting msgpack<2.0.0,>=1.0.0\r\n  Using cached msgpack-1.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\r\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.9/site-packages (from ray[tune]==2.0.1->NeuralForecast) (3.3.1)\r\nCollecting grpcio<=1.43.0,>=1.32.0\r\n  Using cached grpcio-1.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\r\nRequirement already satisfied: attrs in /databricks/python3/lib/python3.9/site-packages (from ray[tune]==2.0.1->NeuralForecast) (21.2.0)\r\nCollecting aiosignal\r\n  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\nCollecting frozenlist\r\n  Using cached frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\r\nRequirement already satisfied: click<=8.0.4,>=7.0 in /databricks/python3/lib/python3.9/site-packages (from ray[tune]==2.0.1->NeuralForecast) (8.0.3)\r\nRequirement already satisfied: virtualenv in /usr/local/lib/python3.9/dist-packages (from ray[tune]==2.0.1->NeuralForecast) (20.8.0)\r\nRequirement already satisfied: requests in /databricks/python3/lib/python3.9/site-packages (from ray[tune]==2.0.1->NeuralForecast) (2.26.0)\r\nRequirement already satisfied: jsonschema in /databricks/python3/lib/python3.9/site-packages (from ray[tune]==2.0.1->NeuralForecast) (3.2.0)\r\nRequirement already satisfied: tabulate in /databricks/python3/lib/python3.9/site-packages (from ray[tune]==2.0.1->NeuralForecast) (0.8.9)\r\nCollecting tensorboardX>=1.9\r\n  Using cached tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\r\nCollecting aiohttp\r\n  Using cached aiohttp-3.8.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\r\nRequirement already satisfied: six>=1.5.2 in /databricks/python3/lib/python3.9/site-packages (from grpcio<=1.43.0,>=1.32.0->ray[tune]==2.0.1->NeuralForecast) (1.16.0)\r\nRequirement already satisfied: pyparsing>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=17.0->pytorch-lightning==1.6.5->NeuralForecast) (3.0.4)\r\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.9/site-packages (from pandas>=1.3.5->NeuralForecast) (2.8.2)\r\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.9/site-packages (from pandas>=1.3.5->NeuralForecast) (2021.3)\r\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (58.0.4)\r\nRequirement already satisfied: markdown>=2.6.8 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (3.3.6)\r\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (0.6.1)\r\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (0.4.6)\r\nRequirement already satisfied: absl-py>=0.4 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (1.0.0)\r\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (1.8.1)\r\nRequirement already satisfied: werkzeug>=1.0.1 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (2.0.2)\r\nRequirement already satisfied: wheel>=0.26 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (0.37.0)\r\nRequirement already satisfied: google-auth<3,>=1.6.3 in /databricks/python3/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (2.6.0)\r\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (5.2.0)\r\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (4.9)\r\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (0.2.8)\r\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /databricks/python3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (1.3.1)\r\nRequirement already satisfied: importlib-metadata>=4.4 in /databricks/python3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (4.8.1)\r\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (3.6.0)\r\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (0.4.8)\r\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests->ray[tune]==2.0.1->NeuralForecast) (3.2)\r\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests->ray[tune]==2.0.1->NeuralForecast) (2.0.4)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests->ray[tune]==2.0.1->NeuralForecast) (1.26.7)\r\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests->ray[tune]==2.0.1->NeuralForecast) (2021.10.8)\r\nRequirement already satisfied: oauthlib>=3.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.5->NeuralForecast) (3.2.0)\r\nCollecting yarl<2.0,>=1.0\r\n  Using cached yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\r\nCollecting async-timeout<5.0,>=4.0.0a3\r\n  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\r\nCollecting multidict<7.0,>=4.5\r\n  Using cached multidict-6.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\r\nRequirement already satisfied: pyrsistent>=0.14.0 in /databricks/python3/lib/python3.9/site-packages (from jsonschema->ray[tune]==2.0.1->NeuralForecast) (0.18.0)\r\nCollecting commonmark<0.10.0,>=0.9.0\r\n  Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\r\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /databricks/python3/lib/python3.9/site-packages (from rich->NeuralForecast) (2.10.0)\r\nRequirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.9/dist-packages (from virtualenv->ray[tune]==2.0.1->NeuralForecast) (2.5.2)\r\nRequirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.9/dist-packages (from virtualenv->ray[tune]==2.0.1->NeuralForecast) (0.3.6)\r\nRequirement already satisfied: backports.entry-points-selectable>=1.0.4 in /usr/local/lib/python3.9/dist-packages (from virtualenv->ray[tune]==2.0.1->NeuralForecast) (1.1.1)\r\nInstalling collected packages: multidict, frozenlist, yarl, typing-extensions, async-timeout, aiosignal, numpy, msgpack, grpcio, aiohttp, torchmetrics, tensorboardX, ray, pyDeprecate, pandas, commonmark, rich, pytorch-lightning, NeuralForecast\r\n  Attempting uninstall: typing-extensions\r\n    Found existing installation: typing-extensions 3.10.0.2\r\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15\r\n    Can't uninstall 'typing-extensions'. No files were found to uninstall.\r\n  Attempting uninstall: numpy\r\n    Found existing installation: numpy 1.20.3\r\n    Not uninstalling numpy at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15\r\n    Can't uninstall 'numpy'. No files were found to uninstall.\r\n  Attempting uninstall: grpcio\r\n    Found existing installation: grpcio 1.44.0\r\n    Not uninstalling grpcio at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15\r\n    Can't uninstall 'grpcio'. No files were found to uninstall.\r\n  Attempting uninstall: pandas\r\n    Found existing installation: pandas 1.3.4\r\n    Not uninstalling pandas at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15\r\n    Can't uninstall 'pandas'. No files were found to uninstall.\r\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\npetastorm 0.11.4 requires pyspark>=2.1.0, which is not installed.\r\nscipy 1.7.1 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.5 which is incompatible.\r\nnumba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.23.5 which is incompatible.\r\nmleap 0.20.0 requires scikit-learn<0.23.0,>=0.22.0, but you have scikit-learn 0.24.2 which is incompatible.\u001B[0m\r\nSuccessfully installed NeuralForecast-1.1.0 aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 commonmark-0.9.1 frozenlist-1.3.3 grpcio-1.43.0 msgpack-1.0.4 multidict-6.0.3 numpy-1.23.5 pandas-1.5.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.5 ray-2.0.1 rich-12.6.0 tensorboardX-2.5.1 torchmetrics-0.11.0 typing-extensions-4.4.0 yarl-1.8.2\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"]}}],"execution_count":0},{"cell_type":"code","source":["!pip install optuna"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8fb27a65-fb32-4288-9777-1796e1d9619b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Collecting optuna\r\n  Using cached optuna-3.0.4-py3-none-any.whl (348 kB)\r\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15/lib/python3.9/site-packages (from optuna) (1.23.5)\r\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.9/site-packages (from optuna) (21.0)\r\nRequirement already satisfied: scipy<1.9.0,>=1.7.0 in /databricks/python3/lib/python3.9/site-packages (from optuna) (1.7.1)\r\nCollecting cmaes>=0.8.2\r\n  Using cached cmaes-0.9.0-py3-none-any.whl (23 kB)\r\nCollecting alembic>=1.5.0\r\n  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\r\nRequirement already satisfied: importlib-metadata<5.0.0 in /databricks/python3/lib/python3.9/site-packages (from optuna) (4.8.1)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.9/site-packages (from optuna) (4.62.3)\r\nCollecting sqlalchemy>=1.3.0\r\n  Using cached SQLAlchemy-1.4.44-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\r\nCollecting cliff\r\n  Using cached cliff-4.1.0-py3-none-any.whl (81 kB)\r\nCollecting colorlog\r\n  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\r\nRequirement already satisfied: PyYAML in /databricks/python3/lib/python3.9/site-packages (from optuna) (6.0)\r\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (1.2.0)\r\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.9/site-packages (from importlib-metadata<5.0.0->optuna) (3.6.0)\r\nRequirement already satisfied: pyparsing>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=20.0->optuna) (3.0.4)\r\nCollecting numpy\r\n  Using cached numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\r\nCollecting greenlet!=0.4.17\r\n  Using cached greenlet-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (535 kB)\r\nCollecting cmd2>=1.0.0\r\n  Using cached cmd2-2.4.2-py3-none-any.whl (147 kB)\r\nCollecting PrettyTable>=0.7.2\r\n  Using cached prettytable-3.5.0-py3-none-any.whl (26 kB)\r\nCollecting autopage>=0.4.0\r\n  Using cached autopage-0.5.1-py3-none-any.whl (29 kB)\r\nCollecting stevedore>=2.0.1\r\n  Using cached stevedore-4.1.1-py3-none-any.whl (50 kB)\r\nCollecting pyperclip>=1.6\r\n  Using cached pyperclip-1.8.2-py3-none-any.whl\r\nRequirement already satisfied: attrs>=16.3.0 in /databricks/python3/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\r\nRequirement already satisfied: wcwidth>=0.1.7 in /databricks/python3/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\r\nCollecting pbr!=2.1.0,>=2.0.0\r\n  Using cached pbr-5.11.0-py2.py3-none-any.whl (112 kB)\r\nRequirement already satisfied: MarkupSafe>=0.9.2 in /databricks/python3/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\r\nInstalling collected packages: pyperclip, pbr, greenlet, stevedore, sqlalchemy, PrettyTable, numpy, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\r\n  Attempting uninstall: numpy\r\n    Found existing installation: numpy 1.23.5\r\n    Uninstalling numpy-1.23.5:\r\n      Successfully uninstalled numpy-1.23.5\r\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\npetastorm 0.11.4 requires pyspark>=2.1.0, which is not installed.\r\nnumba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.22.4 which is incompatible.\r\nmleap 0.20.0 requires scikit-learn<0.23.0,>=0.22.0, but you have scikit-learn 0.24.2 which is incompatible.\u001B[0m\r\nSuccessfully installed PrettyTable-3.5.0 alembic-1.8.1 autopage-0.5.1 cliff-4.1.0 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 greenlet-2.0.1 numpy-1.22.4 optuna-3.0.4 pbr-5.11.0 pyperclip-1.8.2 sqlalchemy-1.4.44 stevedore-4.1.1\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Collecting optuna\r\n  Using cached optuna-3.0.4-py3-none-any.whl (348 kB)\r\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15/lib/python3.9/site-packages (from optuna) (1.23.5)\r\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.9/site-packages (from optuna) (21.0)\r\nRequirement already satisfied: scipy<1.9.0,>=1.7.0 in /databricks/python3/lib/python3.9/site-packages (from optuna) (1.7.1)\r\nCollecting cmaes>=0.8.2\r\n  Using cached cmaes-0.9.0-py3-none-any.whl (23 kB)\r\nCollecting alembic>=1.5.0\r\n  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\r\nRequirement already satisfied: importlib-metadata<5.0.0 in /databricks/python3/lib/python3.9/site-packages (from optuna) (4.8.1)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.9/site-packages (from optuna) (4.62.3)\r\nCollecting sqlalchemy>=1.3.0\r\n  Using cached SQLAlchemy-1.4.44-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\r\nCollecting cliff\r\n  Using cached cliff-4.1.0-py3-none-any.whl (81 kB)\r\nCollecting colorlog\r\n  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\r\nRequirement already satisfied: PyYAML in /databricks/python3/lib/python3.9/site-packages (from optuna) (6.0)\r\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (1.2.0)\r\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.9/site-packages (from importlib-metadata<5.0.0->optuna) (3.6.0)\r\nRequirement already satisfied: pyparsing>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=20.0->optuna) (3.0.4)\r\nCollecting numpy\r\n  Using cached numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\r\nCollecting greenlet!=0.4.17\r\n  Using cached greenlet-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (535 kB)\r\nCollecting cmd2>=1.0.0\r\n  Using cached cmd2-2.4.2-py3-none-any.whl (147 kB)\r\nCollecting PrettyTable>=0.7.2\r\n  Using cached prettytable-3.5.0-py3-none-any.whl (26 kB)\r\nCollecting autopage>=0.4.0\r\n  Using cached autopage-0.5.1-py3-none-any.whl (29 kB)\r\nCollecting stevedore>=2.0.1\r\n  Using cached stevedore-4.1.1-py3-none-any.whl (50 kB)\r\nCollecting pyperclip>=1.6\r\n  Using cached pyperclip-1.8.2-py3-none-any.whl\r\nRequirement already satisfied: attrs>=16.3.0 in /databricks/python3/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\r\nRequirement already satisfied: wcwidth>=0.1.7 in /databricks/python3/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\r\nCollecting pbr!=2.1.0,>=2.0.0\r\n  Using cached pbr-5.11.0-py2.py3-none-any.whl (112 kB)\r\nRequirement already satisfied: MarkupSafe>=0.9.2 in /databricks/python3/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\r\nInstalling collected packages: pyperclip, pbr, greenlet, stevedore, sqlalchemy, PrettyTable, numpy, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\r\n  Attempting uninstall: numpy\r\n    Found existing installation: numpy 1.23.5\r\n    Uninstalling numpy-1.23.5:\r\n      Successfully uninstalled numpy-1.23.5\r\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\npetastorm 0.11.4 requires pyspark>=2.1.0, which is not installed.\r\nnumba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.22.4 which is incompatible.\r\nmleap 0.20.0 requires scikit-learn<0.23.0,>=0.22.0, but you have scikit-learn 0.24.2 which is incompatible.\u001B[0m\r\nSuccessfully installed PrettyTable-3.5.0 alembic-1.8.1 autopage-0.5.1 cliff-4.1.0 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 greenlet-2.0.1 numpy-1.22.4 optuna-3.0.4 pbr-5.11.0 pyperclip-1.8.2 sqlalchemy-1.4.44 stevedore-4.1.1\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-0a79110c-753f-4018-8a49-ce77d655ed15/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Importamos librerias necesarias\nimport numpy as np\nimport pandas as pd\nfrom neuralforecast.utils import AirPassengersDF\nfrom IPython.display import display, Markdown\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import LSTM, NHITS, RNN, GRU, TFT, DilatedRNN\nfrom neuralforecast.auto import AutoLSTM\nfrom neuralforecast.losses.pytorch import MAPE\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport optuna\nfrom pprint import pformat\n\nimport mlflow"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a746f2c0-debf-441a-9fc7-e3cf86a2d1e8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df =  pd.read_csv('https://raw.githubusercontent.com/carlosvelv/temp/main/DatasetHMO_01012016_29092022.csv')\ndf.head()\n#Data cleaning\ndf.drop_duplicates(subset = ['Date'], inplace=True)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.query('Date < 20220801')\ndf = df[df.Demand != 0].copy()\ndf.set_index('Date', inplace = True)\ndf = df.asfreq('H', method='pad')\ndf['Mes'] = df.index.month\ndf['Semana'] = df.index.weekofyear\ndf['Dia'] = df.index.weekday\ndf['Hora'] = df.index.hour\ndf.reset_index( inplace=True)\n\n#Columnas a usar\ncols = ['Date','Demand', 'Temperature', 'Semana', 'Dia', 'Hora']\n\ndf = df[cols].copy()\ndf.fillna(df.mean(), inplace=True)\ndf.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d63bb1bc-7462-44ea-ac68-6a6b5f325b2f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Demand</th>\n      <th>Temperature</th>\n      <th>Semana</th>\n      <th>Dia</th>\n      <th>Hora</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01-02 00:00:00</td>\n      <td>225.622</td>\n      <td>12.1</td>\n      <td>53</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01-02 01:00:00</td>\n      <td>213.620</td>\n      <td>11.2</td>\n      <td>53</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01-02 02:00:00</td>\n      <td>207.360</td>\n      <td>10.3</td>\n      <td>53</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01-02 03:00:00</td>\n      <td>201.374</td>\n      <td>9.4</td>\n      <td>53</td>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01-02 04:00:00</td>\n      <td>199.018</td>\n      <td>9.2</td>\n      <td>53</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Demand</th>\n      <th>Temperature</th>\n      <th>Semana</th>\n      <th>Dia</th>\n      <th>Hora</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01-02 00:00:00</td>\n      <td>225.622</td>\n      <td>12.1</td>\n      <td>53</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01-02 01:00:00</td>\n      <td>213.620</td>\n      <td>11.2</td>\n      <td>53</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01-02 02:00:00</td>\n      <td>207.360</td>\n      <td>10.3</td>\n      <td>53</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01-02 03:00:00</td>\n      <td>201.374</td>\n      <td>9.4</td>\n      <td>53</td>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01-02 04:00:00</td>\n      <td>199.018</td>\n      <td>9.2</td>\n      <td>53</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df.rename({'Date':'ds', 'Demand':'y'}, axis=1, inplace=True)\ndf['unique_id'] = 1.0\ndf"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"71e72ab8-5b01-48a5-9f07-e7efaba49b2b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ds</th>\n      <th>y</th>\n      <th>Temperature</th>\n      <th>Semana</th>\n      <th>Dia</th>\n      <th>Hora</th>\n      <th>unique_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01-02 00:00:00</td>\n      <td>225.622</td>\n      <td>12.1</td>\n      <td>53</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01-02 01:00:00</td>\n      <td>213.620</td>\n      <td>11.2</td>\n      <td>53</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01-02 02:00:00</td>\n      <td>207.360</td>\n      <td>10.3</td>\n      <td>53</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01-02 03:00:00</td>\n      <td>201.374</td>\n      <td>9.4</td>\n      <td>53</td>\n      <td>5</td>\n      <td>3</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01-02 04:00:00</td>\n      <td>199.018</td>\n      <td>9.2</td>\n      <td>53</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57667</th>\n      <td>2022-07-31 19:00:00</td>\n      <td>610.326</td>\n      <td>24.7</td>\n      <td>30</td>\n      <td>6</td>\n      <td>19</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>57668</th>\n      <td>2022-07-31 20:00:00</td>\n      <td>609.114</td>\n      <td>26.4</td>\n      <td>30</td>\n      <td>6</td>\n      <td>20</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>57669</th>\n      <td>2022-07-31 21:00:00</td>\n      <td>610.594</td>\n      <td>26.3</td>\n      <td>30</td>\n      <td>6</td>\n      <td>21</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>57670</th>\n      <td>2022-07-31 22:00:00</td>\n      <td>619.377</td>\n      <td>26.6</td>\n      <td>30</td>\n      <td>6</td>\n      <td>22</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>57671</th>\n      <td>2022-07-31 23:00:00</td>\n      <td>621.581</td>\n      <td>26.1</td>\n      <td>30</td>\n      <td>6</td>\n      <td>23</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>57672 rows × 7 columns</p>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ds</th>\n      <th>y</th>\n      <th>Temperature</th>\n      <th>Semana</th>\n      <th>Dia</th>\n      <th>Hora</th>\n      <th>unique_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01-02 00:00:00</td>\n      <td>225.622</td>\n      <td>12.1</td>\n      <td>53</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01-02 01:00:00</td>\n      <td>213.620</td>\n      <td>11.2</td>\n      <td>53</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01-02 02:00:00</td>\n      <td>207.360</td>\n      <td>10.3</td>\n      <td>53</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01-02 03:00:00</td>\n      <td>201.374</td>\n      <td>9.4</td>\n      <td>53</td>\n      <td>5</td>\n      <td>3</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01-02 04:00:00</td>\n      <td>199.018</td>\n      <td>9.2</td>\n      <td>53</td>\n      <td>5</td>\n      <td>4</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57667</th>\n      <td>2022-07-31 19:00:00</td>\n      <td>610.326</td>\n      <td>24.7</td>\n      <td>30</td>\n      <td>6</td>\n      <td>19</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>57668</th>\n      <td>2022-07-31 20:00:00</td>\n      <td>609.114</td>\n      <td>26.4</td>\n      <td>30</td>\n      <td>6</td>\n      <td>20</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>57669</th>\n      <td>2022-07-31 21:00:00</td>\n      <td>610.594</td>\n      <td>26.3</td>\n      <td>30</td>\n      <td>6</td>\n      <td>21</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>57670</th>\n      <td>2022-07-31 22:00:00</td>\n      <td>619.377</td>\n      <td>26.6</td>\n      <td>30</td>\n      <td>6</td>\n      <td>22</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>57671</th>\n      <td>2022-07-31 23:00:00</td>\n      <td>621.581</td>\n      <td>26.1</td>\n      <td>30</td>\n      <td>6</td>\n      <td>23</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>57672 rows × 7 columns</p>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["train_df = df.query('ds < 20220601')\ntest_df = df.query('ds >= 20220601')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"21ff2c08-bc8d-4c9a-9bec-0f5dcd133871","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Obtain hyperparameters for this trial\ndef suggest_hyperparameters(trial):\n    # Obtain the learning rate on a logarithmic scale\n    max_epochs = trial.suggest_categorical(\"max_epochs\", [200,300,400,500, 600])\n    #Scaler\n    scaler = trial.suggest_categorical(\"scaler\", ['standard'])\n    #lr\n    lr = trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True)\n    # Obtain the dropout ratio in a range from 0.0 to 0.9 with step size 0.1\n    #input_size = trial.suggest_float(\"dropout\", 0.2, 0.9, step=0.1)\n    # Obtain the optimizer to use by name\n    #optimizer_name = trial.suggest_categorical(\"optimizer_name\", [\"Adam\", \"Adadelta\", \"RMSprop\", \"SGD\"])\n    \n    #Encoder decoder params\n    encoder_n_layers = trial.suggest_categorical('encoder_n_layers', [2,3,4,5])\n    \n    encoder_hidden_size = trial.suggest_categorical('encoder_hidden_size', [200,250,300,350])\n    \n    encoder_activation = trial.suggest_categorical('encoder_activation', ['tanh', 'relu'])\n    \n    context_size = trial.suggest_categorical('context_size', [10,20,30,40,50])\n    \n    decoder_hidden_size = trial.suggest_categorical('decoder_hidden_size', [200,250,300,350])\n\n    print(f\"Suggested hyperparameters: \\n{pformat(trial.params)}\")\n    return max_epochs, scaler, lr, encoder_n_layers, encoder_hidden_size, encoder_activation, context_size, decoder_hidden_size"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"67d570bc-cc2a-4759-ae80-8873f8fb0d6b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def objective(trial):\n    print(\"\\n********************************\\n\")\n    best_val_loss = float('Inf')\n    \n    #Fixed params\n    selected_attr = ['Demand', 'Temperature', 'Semana', 'Dia', 'Hora'] \n    nombre_corrida = 'Pruebas para RNN'\n    experiment_path = \"/carlos.velazquez.unison@cenace.gob.mx/LSTM-HMO/hyperparam_opt/benchmarking\"\n    horizon = 24\n    input_size = -1\n    \n    \n\n    experiment = mlflow.set_experiment(experiment_path)\n    with mlflow.start_run(run_name=nombre_corrida) as run:\n\n        \n        max_epochs, scaler, lr, encoder_n_layers, encoder_hidden_size, encoder_activation, context_size, decoder_hidden_size = suggest_hyperparameters(trial)\n    \n        \n        mlflow.log_params(trial.params)\n        \n        ### Loggeando Parametros ###\n        mlflow.log_param('model', 'RNN')\n        mlflow.log_param('horizon', horizon)\n        mlflow.log_param('input_size', input_size)\n        mlflow.log_param('attr', selected_attr)    \n\n\n        ### Generando serie de entrenamiento ###\n        train_df = df.query('ds < 20220601')\n        test_df = df.query('ds >= 20220601')\n\n        #### Generando el modelo\n        models = [RNN(h=horizon, input_size=input_size,\n                #loss=MAE(),\n                loss=MAPE(),\n                #loss=DistributionLoss(distribution='Normal', level=[80, 90]),\n                scaler_type='standard',\n                encoder_n_layers=encoder_n_layers,\n                encoder_hidden_size=encoder_hidden_size,\n                context_size=context_size,\n                decoder_hidden_size=decoder_hidden_size,\n                decoder_layers=2,\n                max_epochs=max_epochs,\n                hist_exog_list=['Temperature', 'Semana', 'Dia', 'Hora'])]\n\n\n        fcst = NeuralForecast(models=models, freq='H')\n        fcst.fit(df=train_df, )\n        forecasts = fcst.predict()\n        \n        forecasts.set_index('ds', inplace=True)\n        plot_df = forecasts.join(test_df.set_index('ds').y)\n\n        \n\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=plot_df.index, y=plot_df.RNN, name=\"Estimada\"))\n        fig.add_trace(go.Scatter(x=plot_df.index, y=plot_df.y, name=\"Real\"))\n        fig.update_layout(title=\"Estimación de la demanda\")\n\n\n        #Logeando grafica\n        mlflow.log_figure(fig, \"real_vs_estimado.html\")\n\n        actual = plot_df.y.values\n        pred = plot_df.RNN.values\n        ape = np.abs((actual - pred) / actual)\n        mape = np.mean(ape) * 100\n        \n        mlflow.log_metric('MAPE', mape)\n\n\n        mlflow.end_run()\n    \n    return mape"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"130cd8f5-8f46-4c37-87bd-18b712edb875","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def main():\n    # Create the optuna study which shares the experiment name\n    study = optuna.create_study(study_name=\"mlflow-optuna\", direction=\"minimize\")\n    study.optimize(objective, n_trials=5)\n\n    # Print optuna study statistics\n    print(\"\\n++++++++++++++++++++++++++++++++++\\n\")\n    print(\"Study statistics: \")\n    print(\"  Number of finished trials: \", len(study.trials))\n\n    print(\"Best trial:\")\n    trial = study.best_trial\n\n    print(\"  Trial number: \", trial.number)\n    print(\"  Loss (trial value): \", trial.value)\n\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bc768815-22fa-4c60-ab4b-e16e1da2417c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%%capture\nmain()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5d0dcd9e-9874-42d4-b9bf-fbc8b085cc63","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\u001B[32m[I 2022-12-07 00:30:08,526]\u001B[0m A new study created in memory with name: mlflow-optuna\u001B[0m\n\u001B[32m[I 2022-12-07 01:15:32,380]\u001B[0m Trial 0 finished with value: 16.40240137853695 and parameters: {'max_epochs': 200, 'scaler': 'standard', 'lr': 0.02331549532163362, 'encoder_n_layers': 4, 'encoder_hidden_size': 350, 'encoder_activation': 'tanh', 'context_size': 10, 'decoder_hidden_size': 350}. Best is trial 0 with value: 16.40240137853695.\u001B[0m\n\u001B[32m[I 2022-12-07 01:39:25,716]\u001B[0m Trial 1 finished with value: 10.189826050358358 and parameters: {'max_epochs': 200, 'scaler': 'standard', 'lr': 0.00013562861047263175, 'encoder_n_layers': 3, 'encoder_hidden_size': 350, 'encoder_activation': 'tanh', 'context_size': 20, 'decoder_hidden_size': 350}. Best is trial 1 with value: 10.189826050358358.\u001B[0m\n\u001B[32m[I 2022-12-07 01:43:46,195]\u001B[0m Trial 2 finished with value: 4.348296275876475 and parameters: {'max_epochs': 300, 'scaler': 'standard', 'lr': 0.052817254520869744, 'encoder_n_layers': 3, 'encoder_hidden_size': 200, 'encoder_activation': 'tanh', 'context_size': 10, 'decoder_hidden_size': 300}. Best is trial 2 with value: 4.348296275876475.\u001B[0m\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[32m[I 2022-12-07 00:30:08,526]\u001B[0m A new study created in memory with name: mlflow-optuna\u001B[0m\n\u001B[32m[I 2022-12-07 01:15:32,380]\u001B[0m Trial 0 finished with value: 16.40240137853695 and parameters: {'max_epochs': 200, 'scaler': 'standard', 'lr': 0.02331549532163362, 'encoder_n_layers': 4, 'encoder_hidden_size': 350, 'encoder_activation': 'tanh', 'context_size': 10, 'decoder_hidden_size': 350}. Best is trial 0 with value: 16.40240137853695.\u001B[0m\n\u001B[32m[I 2022-12-07 01:39:25,716]\u001B[0m Trial 1 finished with value: 10.189826050358358 and parameters: {'max_epochs': 200, 'scaler': 'standard', 'lr': 0.00013562861047263175, 'encoder_n_layers': 3, 'encoder_hidden_size': 350, 'encoder_activation': 'tanh', 'context_size': 20, 'decoder_hidden_size': 350}. Best is trial 1 with value: 10.189826050358358.\u001B[0m\n\u001B[32m[I 2022-12-07 01:43:46,195]\u001B[0m Trial 2 finished with value: 4.348296275876475 and parameters: {'max_epochs': 300, 'scaler': 'standard', 'lr': 0.052817254520869744, 'encoder_n_layers': 3, 'encoder_hidden_size': 200, 'encoder_activation': 'tanh', 'context_size': 10, 'decoder_hidden_size': 300}. Best is trial 2 with value: 4.348296275876475.\u001B[0m\n"]}}],"execution_count":0}],"metadata":{"language_info":{"name":"python"},"application/vnd.databricks.v1+notebook":{"notebookName":"Hyperparam-Optimization-RNN","dashboards":[],"notebookMetadata":{"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":2583149983425875,"dataframes":["_sqldf"]},"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":381526825037127}},"nbformat":4,"nbformat_minor":0}
